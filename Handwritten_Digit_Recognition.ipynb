{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Digit Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnXEpJ6OoPxDq7D/eF4zeW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nzaya/Handwritten-Digit-Recognition/blob/master/Handwritten_Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYuXDOAzXWyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j62KmKdZXc6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the data, split between train and test sets\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0TDZL0Mg_mO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17d8322f-5416-4ccc-9f6e-37c046888a3a"
      },
      "source": [
        "# Print shape\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONUZl3chI339",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "aab9b89f-b495-4a33-df0e-10b58a4bce27"
      },
      "source": [
        "# PLot the first six samples of MNIST training dataset as gray scale image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "for i in range(6):\n",
        "  plt.subplot(int('23' + str(i+1)))\n",
        "  plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ddbwtNZMAC",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOwA-ClxZUkg",
        "colab_type": "text"
      },
      "source": [
        "The dimension of the training data is (60000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS_zWA0_XdFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape to samples*pixels*width*height\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
        "input_shape = (28,28,1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gis0Fop6LYmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One Hot Encode\n",
        "# We require all input and output variables to be numeric\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes = 10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes = 10)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ0TZAlUdaJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e736de4e-15c6-46a3-875a-a867eadad0f5"
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAni1NKJMobm",
        "colab_type": "text"
      },
      "source": [
        "We need to normalize inputs from 0–255 to 0–1 as to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of value. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpBE9PUEcoZ5",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gLoCIAGc3Rb",
        "colab_type": "text"
      },
      "source": [
        "We will create our CNN Model because it generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. We will then compile the model with the Adadelta optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20OXaPQU2OxS",
        "colab_type": "text"
      },
      "source": [
        "First, we define the model to be a sequential model. We stack Convolutional Layer and Pooling Layer on top of each other along with Dropout layer.\n",
        "\n",
        " Dropout layers provide a simple way to avoid overfitting by randomly dropping components of neural network (outputs) from a layer of neural network.\n",
        "\n",
        "This results in a scenario where at each layer more neurons are forced to learn the multiple characteristics of the neural network. The last layer of the neural network will have number of node equal to the number of output class i.e. 10 and the activation function we will be using is “softmax”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVYg6-AgZ2we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neural networks perform much better when the output label is fed as a sparse matrix \n",
        "#so we convert the y-label for both train and test data as a sparse matrix.\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0HGAZOkifwX",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fFxCYFGZ2yl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "2f11c387-12e2-495b-a58e-bf5ae0c2b251"
      },
      "source": [
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 152s 325ms/step - loss: 2.2909 - accuracy: 0.1472 - val_loss: 2.2662 - val_accuracy: 0.3976\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 153s 326ms/step - loss: 2.2510 - accuracy: 0.2762 - val_loss: 2.2171 - val_accuracy: 0.6063\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 153s 326ms/step - loss: 2.1986 - accuracy: 0.4038 - val_loss: 2.1477 - val_accuracy: 0.7100\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 153s 325ms/step - loss: 2.1213 - accuracy: 0.4997 - val_loss: 2.0437 - val_accuracy: 0.7450\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 153s 325ms/step - loss: 2.0043 - accuracy: 0.5685 - val_loss: 1.8877 - val_accuracy: 0.7601\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 153s 326ms/step - loss: 1.8335 - accuracy: 0.6137 - val_loss: 1.6662 - val_accuracy: 0.7723\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 153s 326ms/step - loss: 1.6101 - accuracy: 0.6444 - val_loss: 1.3959 - val_accuracy: 0.7874\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 153s 326ms/step - loss: 1.3747 - accuracy: 0.6732 - val_loss: 1.1364 - val_accuracy: 0.8001\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 153s 325ms/step - loss: 1.1712 - accuracy: 0.6982 - val_loss: 0.9353 - val_accuracy: 0.8166\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 153s 326ms/step - loss: 1.0261 - accuracy: 0.7196 - val_loss: 0.7949 - val_accuracy: 0.8288\n",
            "The model has successfully trained\n",
            "Saving the model as mnist.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twOYjZpxplvk",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ICcU5OpjXH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07e8b432-f737-4238-a894-3ba2d23fa022"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7949094176292419\n",
            "Test accuracy: 0.8288000226020813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ob3LlIjYEiD",
        "colab_type": "text"
      },
      "source": [
        "# Create GUI to predict digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt05EaR4YRfX",
        "colab_type": "text"
      },
      "source": [
        "The gradio library requires you to define 3 things: a prediction function, an input UI component, and an output UI component. In our case, we can use the built-in Sketchpad component for the input, and the Label component for the output (we’ll set up the Label to show the top 3 classes).\n",
        "\n",
        "We also used live=True , which allows us to get real-time predictions from our model, and capture_session=True , which is needed for backwards compatibility for Tensorflow 1 (if you’re using Tensorflow 2, it doesn’t hurt to leave this line in)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6NJv3CbuH_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "d8be6dbf-dbcb-4588-e920-b28188399a46"
      },
      "source": [
        "!pip install gradio"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gradio) (1.4.1)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.6/dist-packages (from gradio) (2.7.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from gradio) (0.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gradio) (1.18.5)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from gradio) (5.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from gradio) (1.0.5)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.6/dist-packages (from gradio) (1.2.9)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from paramiko->gradio) (3.1.7)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.6/dist-packages (from paramiko->gradio) (3.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from paramiko->gradio) (1.4.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (2.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->gradio) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (49.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython->gradio) (4.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->gradio) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->gradio) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.6/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->gradio) (1.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->gradio) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->gradio) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython->gradio) (0.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6NulmVTt-Y_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gradio as gr\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_ynmHbue1lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(image):\n",
        "    prediction = model.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}\n",
        "\n",
        "sketchpad = gr.inputs.Sketchpad()\n",
        "label = gr.outputs.Label(num_top_classes=3)\n",
        "Interface = gr.Interface(classify, sketchpad, label, live=True, capture_session = True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjweRSqtzuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "4ff32f87-1137-4a14-deef-9e957d8d13a9"
      },
      "source": [
        "Interface.launch()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on External URL: https://40215.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://40215.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7facdc0dec50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.networking.serve_files_in_background.<locals>.HTTPServer at 0x7facdc203588>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://40215.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw2EJYoXt08W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}